
<!DOCTYPE html>

<html>
  <head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" /><meta name="generator" content="Docutils 0.17.1: http://docutils.sourceforge.net/" />

    <title>ibm_watson.speech_to_text_v1_adapter module &#8212; Watson Developer Cloud Python SDK 5.2.0 documentation</title>
    <link rel="stylesheet" href="../_static/pygments.css" type="text/css" />
    <link rel="stylesheet" href="../_static/alabaster.css" type="text/css" />
    <script id="documentation_options" data-url_root="../" src="../_static/documentation_options.js"></script>
    <script src="../_static/jquery.js"></script>
    <script src="../_static/underscore.js"></script>
    <script src="../_static/doctools.js"></script>
    <link rel="shortcut icon" href="../_static/favicon.ico"/>
    <link rel="index" title="Index" href="../genindex.html" />
    <link rel="search" title="Search" href="../search.html" />
    <link rel="next" title="ibm_watson.text_to_speech_adapter_v1 module" href="ibm_watson.text_to_speech_adapter_v1.html" />
    <link rel="prev" title="ibm_watson.speech_to_text_v1 module" href="ibm_watson.speech_to_text_v1.html" />
   
  <link rel="stylesheet" href="../_static/custom.css" type="text/css" />
  
  
  <meta name="viewport" content="width=device-width, initial-scale=0.9, maximum-scale=0.9" />

  </head><body>
  

    <div class="document">
      <div class="documentwrapper">
        <div class="bodywrapper">
          

          <div class="body" role="main">
            
  <section id="module-ibm_watson.speech_to_text_v1_adapter">
<span id="ibm-watson-speech-to-text-v1-adapter-module"></span><h1>ibm_watson.speech_to_text_v1_adapter module<a class="headerlink" href="#module-ibm_watson.speech_to_text_v1_adapter" title="Permalink to this headline">¶</a></h1>
<dl class="py class">
<dt id="ibm_watson.speech_to_text_v1_adapter.SpeechToTextV1Adapter">
<em class="property"><span class="pre">class</span> </em><code class="sig-name descname"><span class="pre">SpeechToTextV1Adapter</span></code><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">authenticator</span></span><span class="p"><span class="pre">:</span></span> <span class="n"><span class="pre">Optional</span><span class="p"><span class="pre">[</span></span><span class="pre">ibm_cloud_sdk_core.authenticators.authenticator.Authenticator</span><span class="p"><span class="pre">]</span></span></span> <span class="o"><span class="pre">=</span></span> <span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">service_name</span></span><span class="p"><span class="pre">:</span></span> <span class="n"><a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#str" title="(in Python v3.9)"><span class="pre">str</span></a></span> <span class="o"><span class="pre">=</span></span> <span class="default_value"><span class="pre">'speech_to_text'</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/ibm_watson/speech_to_text_v1_adapter.html#SpeechToTextV1Adapter"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#ibm_watson.speech_to_text_v1_adapter.SpeechToTextV1Adapter" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <a class="reference internal" href="ibm_watson.speech_to_text_v1.html#ibm_watson.speech_to_text_v1.SpeechToTextV1" title="ibm_watson.speech_to_text_v1.SpeechToTextV1"><code class="xref py py-class docutils literal notranslate"><span class="pre">ibm_watson.speech_to_text_v1.SpeechToTextV1</span></code></a></p>
<dl class="py method">
<dt id="ibm_watson.speech_to_text_v1_adapter.SpeechToTextV1Adapter.recognize_using_websocket">
<code class="sig-name descname"><span class="pre">recognize_using_websocket</span></code><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">audio</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">content_type</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">recognize_callback</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">model</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">language_customization_id</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">acoustic_customization_id</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">customization_weight</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">base_model_version</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">inactivity_timeout</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">interim_results</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">keywords</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">keywords_threshold</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">max_alternatives</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">word_alternatives_threshold</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">word_confidence</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">timestamps</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">profanity_filter</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">smart_formatting</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">speaker_labels</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">http_proxy_host</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">http_proxy_port</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">customization_id</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">grammar_name</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">redaction</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">processing_metrics</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">processing_metrics_interval</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">audio_metrics</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">end_of_phrase_silence_time</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">split_transcript_at_phrase_end</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">speech_detector_sensitivity</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">background_audio_suppression</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">low_latency</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">**</span></span><span class="n"><span class="pre">kwargs</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/ibm_watson/speech_to_text_v1_adapter.html#SpeechToTextV1Adapter.recognize_using_websocket"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#ibm_watson.speech_to_text_v1_adapter.SpeechToTextV1Adapter.recognize_using_websocket" title="Permalink to this definition">¶</a></dt>
<dd><p>Sends audio for speech recognition using web sockets.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>audio</strong> (<a class="reference internal" href="ibm_watson.websocket.audio_source.html#ibm_watson.websocket.audio_source.AudioSource" title="ibm_watson.websocket.audio_source.AudioSource"><em>AudioSource</em></a>) – The audio to transcribe in the format specified by the
<cite>Content-Type</cite> header.</p></li>
<li><p><strong>content_type</strong> (<a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#str" title="(in Python v3.9)"><em>str</em></a>) – The type of the input: audio/basic, audio/flac,
audio/l16, audio/mp3, audio/mpeg, audio/mulaw, audio/ogg, audio/ogg;codecs=opus,
audio/ogg;codecs=vorbis, audio/wav, audio/webm, audio/webm;codecs=opus, or
audio/webm;codecs=vorbis.</p></li>
<li><p><strong>recognize_callback</strong> (<a class="reference internal" href="ibm_watson.websocket.recognize_abstract_callback.html#ibm_watson.websocket.recognize_abstract_callback.RecognizeCallback" title="ibm_watson.websocket.recognize_abstract_callback.RecognizeCallback"><em>RecognizeCallback</em></a>) – The callback method for the websocket.</p></li>
<li><p><strong>model</strong> (<a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#str" title="(in Python v3.9)"><em>str</em></a>) – (optional) The identifier of the model that is to be used
for the recognition request. (<strong>Note:</strong> The model <cite>ar-AR_BroadbandModel</cite> is
deprecated; use <cite>ar-MS_BroadbandModel</cite> instead.) See [Languages and
models](<a class="reference external" href="https://cloud.ibm.com/docs/speech-to-text?topic=speech-to-text-models">https://cloud.ibm.com/docs/speech-to-text?topic=speech-to-text-models</a>)
and [Next-generation languages and
models](<a class="reference external" href="https://cloud.ibm.com/docs/speech-to-text?topic=speech-to-text-models-ng">https://cloud.ibm.com/docs/speech-to-text?topic=speech-to-text-models-ng</a>).</p></li>
<li><p><strong>language_customization_id</strong> (<a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#str" title="(in Python v3.9)"><em>str</em></a>) – (optional) The customization ID
(GUID) of a custom language model that is to be used with the recognition
request. The base model of the specified custom language model must match
the model specified with the <cite>model</cite> parameter. You must make the request
with credentials for the instance of the service that owns the custom
model. By default, no custom language model is used. See [Using a custom
language model for speech
recognition](<a class="reference external" href="https://cloud.ibm.com/docs/speech-to-text?topic=speech-to-text-languageUse">https://cloud.ibm.com/docs/speech-to-text?topic=speech-to-text-languageUse</a>).
<strong>Note:</strong> Use this parameter instead of the deprecated <cite>customization_id</cite>
parameter.</p></li>
<li><p><strong>acoustic_customization_id</strong> (<a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#str" title="(in Python v3.9)"><em>str</em></a>) – (optional) The customization ID
(GUID) of a custom acoustic model that is to be used with the recognition
request. The base model of the specified custom acoustic model must match
the model specified with the <cite>model</cite> parameter. You must make the request
with credentials for the instance of the service that owns the custom
model. By default, no custom acoustic model is used. See [Using a custom
acoustic model for speech
recognition](<a class="reference external" href="https://cloud.ibm.com/docs/speech-to-text?topic=speech-to-text-acousticUse">https://cloud.ibm.com/docs/speech-to-text?topic=speech-to-text-acousticUse</a>).</p></li>
<li><p><strong>base_model_version</strong> (<a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#str" title="(in Python v3.9)"><em>str</em></a>) – (optional) The version of the specified base
model that is to be used with the recognition request. Multiple versions of
a base model can exist when a model is updated for internal improvements.
The parameter is intended primarily for use with custom models that have
been upgraded for a new base model. The default value depends on whether
the parameter is used with or without a custom model. See [Making speech
recognition requests with upgraded custom
models](<a class="reference external" href="https://cloud.ibm.com/docs/speech-to-text?topic=speech-to-text-custom-upgrade-use#custom-upgrade-use-recognition">https://cloud.ibm.com/docs/speech-to-text?topic=speech-to-text-custom-upgrade-use#custom-upgrade-use-recognition</a>).</p></li>
<li><p><strong>customization_weight</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#float" title="(in Python v3.9)"><em>float</em></a>) – (optional) If you specify the
customization ID (GUID) of a custom language model with the recognition
request, the customization weight tells the service how much weight to give
to words from the custom language model compared to those from the base
model for the current request.
Specify a value between 0.0 and 1.0. Unless a different customization
weight was specified for the custom model when it was trained, the default
value is 0.3. A customization weight that you specify overrides a weight
that was specified when the custom model was trained.
The default value yields the best performance in general. Assign a higher
value if your audio makes frequent use of OOV words from the custom model.
Use caution when setting the weight: a higher value can improve the
accuracy of phrases from the custom model’s domain, but it can negatively
affect performance on non-domain phrases.
See [Using customization
weight](<a class="reference external" href="https://cloud.ibm.com/docs/speech-to-text?topic=speech-to-text-languageUse#weight">https://cloud.ibm.com/docs/speech-to-text?topic=speech-to-text-languageUse#weight</a>).</p></li>
<li><p><strong>inactivity_timeout</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.9)"><em>int</em></a>) – (optional) The time in seconds after which,
if only silence (no speech) is detected in streaming audio, the connection
is closed with a 400 error. The parameter is useful for stopping audio
submission from a live microphone when a user simply walks away. Use <cite>-1</cite>
for infinity. See [Inactivity
timeout](<a class="reference external" href="https://cloud.ibm.com/docs/speech-to-text?topic=speech-to-text-input#timeouts-inactivity">https://cloud.ibm.com/docs/speech-to-text?topic=speech-to-text-input#timeouts-inactivity</a>).</p></li>
<li><p><strong>keywords</strong> (<em>List</em><em>[</em><a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#str" title="(in Python v3.9)"><em>str</em></a><em>]</em>) – (optional) An array of keyword strings to spot
in the audio. Each keyword string can include one or more string tokens.
Keywords are spotted only in the final results, not in interim hypotheses.
If you specify any keywords, you must also specify a keywords threshold.
Omit the parameter or specify an empty array if you do not need to spot
keywords.
You can spot a maximum of 1000 keywords with a single request. A single
keyword can have a maximum length of 1024 characters, though the maximum
effective length for double-byte languages might be shorter. Keywords are
case-insensitive.
See [Keyword
spotting](<a class="reference external" href="https://cloud.ibm.com/docs/speech-to-text?topic=speech-to-text-spotting#keyword-spotting">https://cloud.ibm.com/docs/speech-to-text?topic=speech-to-text-spotting#keyword-spotting</a>).</p></li>
<li><p><strong>keywords_threshold</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#float" title="(in Python v3.9)"><em>float</em></a>) – (optional) A confidence value that is the
lower bound for spotting a keyword. A word is considered to match a keyword
if its confidence is greater than or equal to the threshold. Specify a
probability between 0.0 and 1.0. If you specify a threshold, you must also
specify one or more keywords. The service performs no keyword spotting if
you omit either parameter. See [Keyword
spotting](<a class="reference external" href="https://cloud.ibm.com/docs/speech-to-text?topic=speech-to-text-spotting#keyword-spotting">https://cloud.ibm.com/docs/speech-to-text?topic=speech-to-text-spotting#keyword-spotting</a>).</p></li>
<li><p><strong>max_alternatives</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.9)"><em>int</em></a>) – (optional) The maximum number of alternative
transcripts that the service is to return. By default, the service returns
a single transcript. If you specify a value of <cite>0</cite>, the service uses the
default value, <cite>1</cite>. See [Maximum
alternatives](<a class="reference external" href="https://cloud.ibm.com/docs/speech-to-text?topic=speech-to-text-metadata#max-alternatives">https://cloud.ibm.com/docs/speech-to-text?topic=speech-to-text-metadata#max-alternatives</a>).</p></li>
<li><p><strong>word_alternatives_threshold</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#float" title="(in Python v3.9)"><em>float</em></a>) – (optional) A confidence value
that is the lower bound for identifying a hypothesis as a possible word
alternative (also known as “Confusion Networks”). An alternative word is
considered if its confidence is greater than or equal to the threshold.
Specify a probability between 0.0 and 1.0. By default, the service computes
no alternative words. See [Word
alternatives](<a class="reference external" href="https://cloud.ibm.com/docs/speech-to-text?topic=speech-to-text-spotting#word-alternatives">https://cloud.ibm.com/docs/speech-to-text?topic=speech-to-text-spotting#word-alternatives</a>).</p></li>
<li><p><strong>word_confidence</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#bool" title="(in Python v3.9)"><em>bool</em></a>) – (optional) If <cite>true</cite>, the service returns a
confidence measure in the range of 0.0 to 1.0 for each word. By default,
the service returns no word confidence scores. See [Word
confidence](<a class="reference external" href="https://cloud.ibm.com/docs/speech-to-text?topic=speech-to-text-metadata#word-confidence">https://cloud.ibm.com/docs/speech-to-text?topic=speech-to-text-metadata#word-confidence</a>).</p></li>
<li><p><strong>timestamps</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#bool" title="(in Python v3.9)"><em>bool</em></a>) – (optional) If <cite>true</cite>, the service returns time
alignment for each word. By default, no timestamps are returned. See [Word
timestamps](<a class="reference external" href="https://cloud.ibm.com/docs/speech-to-text?topic=speech-to-text-metadata#word-timestamps">https://cloud.ibm.com/docs/speech-to-text?topic=speech-to-text-metadata#word-timestamps</a>).</p></li>
<li><p><strong>profanity_filter</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#bool" title="(in Python v3.9)"><em>bool</em></a>) – (optional) If <cite>true</cite>, the service filters
profanity from all output except for keyword results by replacing
inappropriate words with a series of asterisks. Set the parameter to
<cite>false</cite> to return results with no censoring. Applies to US English and
Japanese transcription only. See [Profanity
filtering](<a class="reference external" href="https://cloud.ibm.com/docs/speech-to-text?topic=speech-to-text-formatting#profanity-filtering">https://cloud.ibm.com/docs/speech-to-text?topic=speech-to-text-formatting#profanity-filtering</a>).</p></li>
<li><p><strong>smart_formatting</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#bool" title="(in Python v3.9)"><em>bool</em></a>) – (optional) If <cite>true</cite>, the service converts
dates, times, series of digits and numbers, phone numbers, currency values,
and internet addresses into more readable, conventional representations in
the final transcript of a recognition request. For US English, the service
also converts certain keyword strings to punctuation symbols. By default,
the service performs no smart formatting.
<strong>Note:</strong> Applies to US English, Japanese, and Spanish transcription only.
See [Smart
formatting](<a class="reference external" href="https://cloud.ibm.com/docs/speech-to-text?topic=speech-to-text-formatting#smart-formatting">https://cloud.ibm.com/docs/speech-to-text?topic=speech-to-text-formatting#smart-formatting</a>).</p></li>
<li><p><strong>speaker_labels</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#bool" title="(in Python v3.9)"><em>bool</em></a>) – (optional) If <cite>true</cite>, the response includes
labels that identify which words were spoken by which participants in a
multi-person exchange. By default, the service returns no speaker labels.
Setting <cite>speaker_labels</cite> to <cite>true</cite> forces the <cite>timestamps</cite> parameter to be
<cite>true</cite>, regardless of whether you specify <cite>false</cite> for the parameter.
* For previous-generation models, can be used for US English, Australian
English, German, Japanese, Korean, and Spanish (both broadband and
narrowband models) and UK English (narrowband model) transcription only.
* For next-generation models, can be used for English (Australian, UK, and
US), German, and Spanish transcription only.
Restrictions and limitations apply to the use of speaker labels for both
types of models. See [Speaker
labels](<a class="reference external" href="https://cloud.ibm.com/docs/speech-to-text?topic=speech-to-text-speaker-labels">https://cloud.ibm.com/docs/speech-to-text?topic=speech-to-text-speaker-labels</a>).</p></li>
<li><p><strong>http_proxy_host</strong> (<a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#str" title="(in Python v3.9)"><em>str</em></a>) – http proxy host name.</p></li>
<li><p><strong>http_proxy_port</strong> (<a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#str" title="(in Python v3.9)"><em>str</em></a>) – http proxy port. If not set, set to 80.</p></li>
<li><p><strong>customization_id</strong> (<a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#str" title="(in Python v3.9)"><em>str</em></a>) – (optional) <strong>Deprecated.</strong> Use the
<cite>language_customization_id</cite> parameter to specify the customization ID
(GUID) of a custom language model that is to be used with the recognition
request. Do not specify both parameters with a request.</p></li>
<li><p><strong>grammar_name</strong> (<a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#str" title="(in Python v3.9)"><em>str</em></a>) – (optional) The name of a grammar that is to be
used with the recognition request. If you specify a grammar, you must also
use the <cite>language_customization_id</cite> parameter to specify the name of the
custom language model for which the grammar is defined. The service
recognizes only strings that are recognized by the specified grammar; it
does not recognize other custom words from the model’s words resource. See
[Using a grammar for speech
recognition](<a class="reference external" href="https://cloud.ibm.com/docs/speech-to-text?topic=speech-to-text-grammarUse">https://cloud.ibm.com/docs/speech-to-text?topic=speech-to-text-grammarUse</a>).</p></li>
<li><p><strong>redaction</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#bool" title="(in Python v3.9)"><em>bool</em></a>) – (optional) If <cite>true</cite>, the service redacts, or masks,
numeric data from final transcripts. The feature redacts any number that
has three or more consecutive digits by replacing each digit with an <cite>X</cite>
character. It is intended to redact sensitive numeric data, such as credit
card numbers. By default, the service performs no redaction.
When you enable redaction, the service automatically enables smart
formatting, regardless of whether you explicitly disable that feature. To
ensure maximum security, the service also disables keyword spotting
(ignores the <cite>keywords</cite> and <cite>keywords_threshold</cite> parameters) and returns
only a single final transcript (forces the <cite>max_alternatives</cite> parameter to
be <cite>1</cite>).
<strong>Note:</strong> Applies to US English, Japanese, and Korean transcription only.
See [Numeric
redaction](<a class="reference external" href="https://cloud.ibm.com/docs/speech-to-text?topic=speech-to-text-formatting#numeric-redaction">https://cloud.ibm.com/docs/speech-to-text?topic=speech-to-text-formatting#numeric-redaction</a>).</p></li>
<li><p><strong>audio_metrics</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#bool" title="(in Python v3.9)"><em>bool</em></a>) – (optional) If <cite>true</cite>, requests detailed
information about the signal characteristics of the input audio. The
service returns audio metrics with the final transcription results. By
default, the service returns no audio metrics.
See [Audio
metrics](<a class="reference external" href="https://cloud.ibm.com/docs/speech-to-text?topic=speech-to-text-metrics#audio-metrics">https://cloud.ibm.com/docs/speech-to-text?topic=speech-to-text-metrics#audio-metrics</a>).</p></li>
<li><p><strong>end_of_phrase_silence_time</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#float" title="(in Python v3.9)"><em>float</em></a>) – (optional) If <cite>true</cite>, specifies
the duration of the pause interval at which the service splits a transcript
into multiple final results. If the service detects pauses or extended
silence before it reaches the end of the audio stream, its response can
include multiple final results. Silence indicates a point at which the
speaker pauses between spoken words or phrases.
Specify a value for the pause interval in the range of 0.0 to 120.0.
* A value greater than 0 specifies the interval that the service is to use
for speech recognition.
* A value of 0 indicates that the service is to use the default interval.
It is equivalent to omitting the parameter.
The default pause interval for most languages is 0.8 seconds; the default
for Chinese is 0.6 seconds.
See [End of phrase silence
time](<a class="reference external" href="https://cloud.ibm.com/docs/speech-to-text?topic=speech-to-text-parsing#silence-time">https://cloud.ibm.com/docs/speech-to-text?topic=speech-to-text-parsing#silence-time</a>).</p></li>
<li><p><strong>split_transcript_at_phrase_end</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#bool" title="(in Python v3.9)"><em>bool</em></a>) – (optional) If <cite>true</cite>, directs
the service to split the transcript into multiple final results based on
semantic features of the input, for example, at the conclusion of
meaningful phrases such as sentences. The service bases its understanding
of semantic features on the base language model that you use with a
request. Custom language models and grammars can also influence how and
where the service splits a transcript. By default, the service splits
transcripts based solely on the pause interval.
See [Split transcript at phrase
end](<a class="reference external" href="https://cloud.ibm.com/docs/speech-to-text?topic=speech-to-text-parsing#split-transcript">https://cloud.ibm.com/docs/speech-to-text?topic=speech-to-text-parsing#split-transcript</a>).</p></li>
<li><p><strong>speech_detector_sensitivity</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#float" title="(in Python v3.9)"><em>float</em></a>) – (optional) The sensitivity of
speech activity detection that the service is to perform. Use the parameter
to suppress word insertions from music, coughing, and other non-speech
events. The service biases the audio it passes for speech recognition by
evaluating the input audio against prior models of speech and non-speech
activity.
Specify a value between 0.0 and 1.0:
* 0.0 suppresses all audio (no speech is transcribed).
* 0.5 (the default) provides a reasonable compromise for the level of
sensitivity.
* 1.0 suppresses no audio (speech detection sensitivity is disabled).
The values increase on a monotonic curve. See [Speech detector
sensitivity](<a class="reference external" href="https://cloud.ibm.com/docs/speech-to-text?topic=speech-to-text-detection#detection-parameters-sensitivity">https://cloud.ibm.com/docs/speech-to-text?topic=speech-to-text-detection#detection-parameters-sensitivity</a>).</p></li>
<li><p><strong>background_audio_suppression</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#float" title="(in Python v3.9)"><em>float</em></a>) – (optional) The level to which
the service is to suppress background audio based on its volume to prevent
it from being transcribed as speech. Use the parameter to suppress side
conversations or background noise.
Specify a value in the range of 0.0 to 1.0:
* 0.0 (the default) provides no suppression (background audio suppression
is disabled).
* 0.5 provides a reasonable level of audio suppression for general usage.
* 1.0 suppresses all audio (no audio is transcribed).
The values increase on a monotonic curve. See [Background audio
suppression](<a class="reference external" href="https://cloud.ibm.com/docs/speech-to-text?topic=speech-to-text-detection#detection-parameters-suppression">https://cloud.ibm.com/docs/speech-to-text?topic=speech-to-text-detection#detection-parameters-suppression</a>).</p></li>
<li><p><strong>low_latency</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#bool" title="(in Python v3.9)"><em>bool</em></a>) – (optional) If <cite>true</cite> for next-generation
<cite>Multimedia</cite> and <cite>Telephony</cite> models that support low latency, directs the
service to produce results even more quickly than it usually does.
Next-generation models produce transcription results faster than
previous-generation models. The <cite>low_latency</cite> parameter causes the models
to produce results even more quickly, though the results might be less
accurate when the parameter is used.
<strong>Note:</strong> The parameter is beta functionality. It is not available for
previous-generation <cite>Broadband</cite> and <cite>Narrowband</cite> models. It is available
only for some next-generation models.
* For a list of next-generation models that support low latency, see
[Supported language
models](<a class="reference external" href="https://cloud.ibm.com/docs/speech-to-text?topic=speech-to-text-models-ng#models-ng-supported">https://cloud.ibm.com/docs/speech-to-text?topic=speech-to-text-models-ng#models-ng-supported</a>)
for next-generation models.
* For more information about the <cite>low_latency</cite> parameter, see [Low
latency](<a class="reference external" href="https://cloud.ibm.com/docs/speech-to-text?topic=speech-to-text-interim#low-latency">https://cloud.ibm.com/docs/speech-to-text?topic=speech-to-text-interim#low-latency</a>).</p></li>
<li><p><strong>headers</strong> (<a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#dict" title="(in Python v3.9)"><em>dict</em></a>) – A <cite>dict</cite> containing the request headers</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p>A <cite>dict</cite> containing the <cite>SpeechRecognitionResults</cite> response.</p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p><a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#dict" title="(in Python v3.9)">dict</a></p>
</dd>
</dl>
</dd></dl>

</dd></dl>

</section>


          </div>
          
        </div>
      </div>
      <div class="sphinxsidebar" role="navigation" aria-label="main navigation">
        <div class="sphinxsidebarwrapper"><h3>Useful Links</h3>
<ul>
  <li><a href="https://www.ibm.com/watson/developercloud/">Watson APIs</a></li>
  <li><a href="http://github.com/watson-developer-cloud/python-sdk">GitHub</a></li>
  <li><a href="http://github.com/watson-developer-cloud/python-sdk/issues">Issue Tracker</a></li>
  <li><a href="http://stackoverflow.com/questions/ask?tags=ibm-watson">StackOverflow</a></li>
</ul><div class="relations">
<h3>Related Topics</h3>
<ul>
  <li><a href="../index.html">Documentation overview</a><ul>
      <li>Previous: <a href="ibm_watson.speech_to_text_v1.html" title="previous chapter">ibm_watson.speech_to_text_v1 module</a></li>
      <li>Next: <a href="ibm_watson.text_to_speech_adapter_v1.html" title="next chapter">ibm_watson.text_to_speech_adapter_v1 module</a></li>
  </ul></li>
</ul>
</div>
<div id="searchbox" style="display: none" role="search">
  <h3 id="searchlabel">Quick search</h3>
    <div class="searchformwrapper">
    <form class="search" action="../search.html" method="get">
      <input type="text" name="q" aria-labelledby="searchlabel" />
      <input type="submit" value="Go" />
    </form>
    </div>
</div>
<script>$('#searchbox').show(0);</script>
        </div>
      </div>
      <div class="clearer"></div>
    </div>
    <div class="footer">
      
      
    </div>

    

    
  </body>
</html>